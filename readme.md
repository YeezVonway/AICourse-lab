# 基于声音识别的守护者机器人

本仓库是北京大学本科课程“人工智能概论”的小组项目仓库。

本小组计划使用深度学习进行声音识别，提取人声特征，识别咳嗽、打喷嚏、尖叫等声音，以此为家庭成员提供远程的智能健康看护功能。

项目一共包含以下几个部分。
+ 一个使用pytorch实现的通用于声音分类任务的深度学习框架。可以在其中搭建模型，并进行测试、调试、训练，提供用于检测的接口。其所有相关文件包在[audio_classification](https://github.com/YeezVonway/AICourse-lab/tree/master/audio_classification)，包括全部源码和说明文档。
+ 一个启动后端神经网络模型和录音功能，不断进行声音识别，并向前端页面输出结果的简单服务器。其源码可见 service.py。同目录下的easyconn.py 和 record.py 是两个为之提供服务器连接、录音功能的辅助代码文件。
+ 一个简单友好的HTML交互页面，用于本机demo展示。其相关文件可见[page](https://github.com/YeezVonway/AICourse-lab/tree/master/page)。用户能够参考它编写自己的交互界面。
+ 搜集咳嗽、打喷嚏、尖叫和无关组的声音样本，用于训练和测试。这些训练数据文件过大，并未提交到仓库。
+ 使用框架训练好模型。我们使用十分有限的样本训练了一个模型，在比较安静的环境中可以比较正常地工作。模型由于文件过大，不便提交到仓库。

## 如何启动后台服务

使用控制台命令`python server.py`来启动后台服务窗口。

在这之前建议：
+ 在audio_classification目录中查阅相关文档，安装python和库。
+ 在audio_classification中阅读文档，修改CONFIG.py，进行参数配置

随后将会弹出一个窗口，可以设置提供服务的端口号。点击启动按钮后，后台将启动模型，挂起并等待前端进行连接。

## 如何进行交互

可以使用chrome浏览器打开我们提供的本地交互界面 page/index.html。如果后台已经启动服务，该页面就能正常工作。

你也可以编写自己的交互界面，或是实现远程交互，只需和后台服务的端口进行连接，后台就会不断地将json格式的预测结果发送到前台。前台可以根据需要进行数据处理和统计。

## 我们训练的模型

我们训练了一个基于ReSE网络的深度神经网络模型，可用于"cough"（咳嗽）,"defult"（无关类）,"scream"（尖叫、吼叫）,"sneeze"（打喷嚏）四个类别的分类。

性能在安静环境下尚可，测试集准确率约为87%，其中对咳嗽检测率令人满意，对喷嚏的检测偏差较大（由于我们的找到的数据集十分有限）。

模型文件已经上传到[云盘](https://pan.baidu.com/s/1o-i2xdQPV0srAnLkjtrMBQ)，提取码为：6nik。

下载好模型后，需要在 audio_classification/CONFIG.py 对路径进行相应配置。

如果模型读取失败或运行过程中出现尺寸错误，可能是因为对配置进行了关键性修改，导致无法适用已有的模型。但我们也提供了自行训练和测试的接口，可在audio_classification中阅读相关文档。